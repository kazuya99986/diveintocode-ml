{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled70.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wBnoS5QGS0y"
      },
      "source": [
        "# Sprint23 LSTM　ver.2\n",
        "※ver1は別途ファイルあり"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNXJBMWVGamc"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTW8B7MSU2oR",
        "outputId": "2692ab63-164b-492c-9e50-0599fcc40e41"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "#データロード\n",
        "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_examples, test_examples = dataset['train'], dataset['test']"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku_KBmX0VjVn"
      },
      "source": [
        "encoder = info.features['text'].encoder"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkgcDeJuXSR8",
        "outputId": "8b97956e-89c1-4c05-9c78-03fef8490659"
      },
      "source": [
        "print('Vocabulary size: {}'.format(encoder.vocab_size))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 8185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EH_oqt6XSUW",
        "outputId": "cc1a00d1-895f-4d46-9798-4c823ee43d2e"
      },
      "source": [
        "sample_string = 'Hello TensorFlow.'\n",
        "\n",
        "encoded_string = encoder.encode(sample_string)\n",
        "print('Encoded string is {}'.format(encoded_string))\n",
        "\n",
        "original_string = encoder.decode(encoded_string)\n",
        "print('The original string: \"{}\"'.format(original_string))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded string is [4025, 222, 6307, 2327, 4043, 2120, 7975]\n",
            "The original string: \"Hello TensorFlow.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuEFfJuZXSW3"
      },
      "source": [
        "assert original_string == sample_string"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6kZPCr5XcBD",
        "outputId": "d555ef29-d245-400b-d7da-a42bfac6f682"
      },
      "source": [
        "for index in encoded_string:\n",
        "  print('{} ----> {}'.format(index, encoder.decode([index])))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4025 ----> Hell\n",
            "222 ----> o \n",
            "6307 ----> Ten\n",
            "2327 ----> sor\n",
            "4043 ----> Fl\n",
            "2120 ----> ow\n",
            "7975 ----> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc0-5AsPbTeR",
        "outputId": "1475b85f-5c63-4583-d128-97d7d3175a57"
      },
      "source": [
        "len(train_examples)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6AWK5vZXcFc"
      },
      "source": [
        "BUFFER_SIZE = 25000 #基本はデータ数と同一でOK。完全にシャッフルしたい場合はデータ数よりも大きい値を指定すべし\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = (train_examples\n",
        "                 .shuffle(BUFFER_SIZE)\n",
        "                 .padded_batch(BATCH_SIZE))\n",
        "\n",
        "test_dataset = (test_examples\n",
        "                .padded_batch(BATCH_SIZE))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwN4XTdQXcHv"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1V9Dp2EXcMj"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TqV7TIJXcO_",
        "outputId": "de480de0-bd4d-4563-8be8-91f85bc69971"
      },
      "source": [
        "history = model.fit(train_dataset, epochs=5,\n",
        "                    validation_data=test_dataset, \n",
        "                    validation_steps=30)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4999WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5c234b7f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5c234b7f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5c234b7f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 [==============================] - 770s 2s/step - loss: 0.6938 - accuracy: 0.4999 - val_loss: 0.6912 - val_accuracy: 0.4917\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 759s 2s/step - loss: 0.6769 - accuracy: 0.5024 - val_loss: 0.6863 - val_accuracy: 0.4958\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 761s 2s/step - loss: 0.6105 - accuracy: 0.6146 - val_loss: 0.6065 - val_accuracy: 0.6578\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 766s 2s/step - loss: 0.3814 - accuracy: 0.8278 - val_loss: 0.4846 - val_accuracy: 0.7526\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 766s 2s/step - loss: 0.2013 - accuracy: 0.9217 - val_loss: 0.5038 - val_accuracy: 0.8167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHQEtRLTS640",
        "outputId": "39c26430-0730-4dac-f4c0-a29823645b98"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 65s 165ms/step - loss: 0.5087 - accuracy: 0.8102\n",
            "Test Loss: 0.5087347030639648\n",
            "Test Accuracy: 0.8102399706840515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqlILVbVY4RH",
        "outputId": "2940f0b4-30e1-4ec7-90be-f671999ce629"
      },
      "source": [
        "def pad_to_size(vec, size):\n",
        "  zeros = [0] * (size - len(vec))\n",
        "  vec.extend(zeros)\n",
        "  return vec\n",
        "\n",
        "def sample_predict(sample_pred_text, pad):\n",
        "  encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
        "\n",
        "  if pad:\n",
        "    encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
        "  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
        "  predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
        "\n",
        "  return (predictions)\n",
        "\n",
        "# パディングなしのサンプルテキストの推論\n",
        "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
        "                    'were out of this world. I would recommend this movie.')\n",
        "predictions = sample_predict(sample_pred_text, pad=False)\n",
        "print(predictions)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5c236bc0e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5c236bc0e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5c236bc0e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "[[1.3492737]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBc4iQa-iIS8"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtV0yNZGhXSz",
        "outputId": "888e7c74-2a5f-496a-c0ec-5ffe796685d8"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_dataset, epochs=20,\n",
        "                    validation_data=test_dataset, \n",
        "                    validation_steps=30)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5000WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5c25164200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5c25164200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5c25164200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 [==============================] - 36s 83ms/step - loss: 0.6914 - accuracy: 0.5000 - val_loss: 0.6855 - val_accuracy: 0.4917\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.5004 - accuracy: 0.7254 - val_loss: 0.3870 - val_accuracy: 0.8286\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.2808 - accuracy: 0.8853 - val_loss: 0.3496 - val_accuracy: 0.8667\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.2207 - accuracy: 0.9140 - val_loss: 0.3674 - val_accuracy: 0.8432\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1917 - accuracy: 0.9290 - val_loss: 0.3889 - val_accuracy: 0.8380\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1669 - accuracy: 0.9400 - val_loss: 0.3864 - val_accuracy: 0.8260\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1477 - accuracy: 0.9491 - val_loss: 0.3770 - val_accuracy: 0.8484\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1376 - accuracy: 0.9530 - val_loss: 0.4326 - val_accuracy: 0.8589\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1246 - accuracy: 0.9581 - val_loss: 0.4684 - val_accuracy: 0.8620\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1128 - accuracy: 0.9631 - val_loss: 0.4616 - val_accuracy: 0.8380\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1039 - accuracy: 0.9670 - val_loss: 0.4995 - val_accuracy: 0.8458\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.1020 - accuracy: 0.9680 - val_loss: 0.5474 - val_accuracy: 0.8354\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.0953 - accuracy: 0.9704 - val_loss: 0.5106 - val_accuracy: 0.8479\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.0839 - accuracy: 0.9762 - val_loss: 0.5790 - val_accuracy: 0.8490\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.0866 - accuracy: 0.9738 - val_loss: 0.5496 - val_accuracy: 0.8417\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 33s 81ms/step - loss: 0.0741 - accuracy: 0.9808 - val_loss: 0.5634 - val_accuracy: 0.8469\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.0732 - accuracy: 0.9798 - val_loss: 0.6199 - val_accuracy: 0.8396\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 33s 81ms/step - loss: 0.0719 - accuracy: 0.9791 - val_loss: 0.6362 - val_accuracy: 0.8391\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.0778 - accuracy: 0.9776 - val_loss: 0.6509 - val_accuracy: 0.8401\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.0667 - accuracy: 0.9820 - val_loss: 0.6721 - val_accuracy: 0.8328\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.6635 - accuracy: 0.8351\n",
            "Test Loss: 0.6634854674339294\n",
            "Test Accuracy: 0.8350800275802612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gbcUEMjiXB-",
        "outputId": "1e847a4b-bd19-4816-8a99-6baaf8b46e25"
      },
      "source": [
        "def pad_to_size(vec, size):\n",
        "  zeros = [0] * (size - len(vec))\n",
        "  vec.extend(zeros)\n",
        "  return vec\n",
        "\n",
        "def sample_predict(sample_pred_text, pad):\n",
        "  encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
        "\n",
        "  if pad:\n",
        "    encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
        "  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
        "  predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
        "\n",
        "  return (predictions)\n",
        "\n",
        "# パディングなしのサンプルテキストの推論\n",
        "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
        "                    'were out of this world. I would recommend this movie.')\n",
        "predictions = sample_predict(sample_pred_text, pad=False)\n",
        "print(predictions)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5c25bc4b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5c25bc4b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5c25bc4b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "[[-0.9470114]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}