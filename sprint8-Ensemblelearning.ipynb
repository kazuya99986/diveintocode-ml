{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled36.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqcnvl-2zEtx"
      },
      "source": [
        "# Sprint8_アンサンブル学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHPFTEPl0Qqh"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('drive/My Drive/data/house-prices-advanced-regression-techniques_train.csv')\n",
        "\n",
        "X = df[['GrLivArea', 'YearBuilt']].values\n",
        "y = df['SalePrice'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wd7fQUJzQ_8"
      },
      "source": [
        "# 【問題1】ブレンディングのスクラッチ実装\n",
        "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証データに対する平均二乗誤差（MSE）が小さくなることを指します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdybjIKL0c0j"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Ridge"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMNkEs-TX0jR",
        "outputId": "7ee46e7b-e27e-4c90-b711-8eb9a0820474"
      },
      "source": [
        "#デフォルト（基準）\n",
        "\n",
        "print('----Default models MSE----')\n",
        "\n",
        "linear = LinearRegression().fit(X_train, y_train)\n",
        "linear_Y_pred = linear.predict(X_test)\n",
        "print(f'LinearRegression; {mean_squared_error(y_test, linear_Y_pred)/ 100000000}') #best（単位：億）\n",
        "\n",
        "svr = SVR().fit(X_train, y_train)\n",
        "svr_Y_pred = svr.predict(X_test)\n",
        "print(f'SVR; {mean_squared_error(y_test, svr_Y_pred)/ 100000000}')\n",
        "\n",
        "tree = DecisionTreeRegressor().fit(X_train, y_train)\n",
        "tree_Y_pred = tree.predict(X_test)\n",
        "print(f'DecisionTreeRegressor; {mean_squared_error(y_test, tree_Y_pred)/ 100000000}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----Default models MSE----\n",
            "LinearRegression; 23.09870747753036\n",
            "SVR; 80.80337267890563\n",
            "DecisionTreeRegressor; 29.96875189784627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V8FJKVtY2Mq",
        "outputId": "69465230-8dfd-4d66-d7f0-e3f58796e1a8"
      },
      "source": [
        "#手法のブレンディング\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, svr, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred], axis=0)\n",
        "print(f'linear, svr; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'svr, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}') #best 単位：億"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear, svr, tree; 29.819944209022392\n",
            "linear, svr; 41.22424759331846\n",
            "svr, tree; 37.79910231171434\n",
            "linear, tree; 21.539232578838142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSVfmWnxiOni",
        "outputId": "04d6d1d0-5044-46aa-d747-0fe96091e312"
      },
      "source": [
        "#標準化のブレンディング\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "linear = LinearRegression().fit(X_train_scaled, y_train)\n",
        "linear_Y_pred = linear.predict(X_test_scaled)\n",
        "print(f'LinearRegression; {mean_squared_error(y_test, linear_Y_pred) / 100000000}')\n",
        "\n",
        "tree = DecisionTreeRegressor(max_depth=5, min_samples_leaf=10).fit(X_train_scaled, y_train)\n",
        "tree_Y_pred = tree.predict(X_test_scaled)\n",
        "print(f'DecisionTreeRegressor; {mean_squared_error(y_test, tree_Y_pred) / 100000000}')\n",
        "\n",
        "svr = SVR(kernel='poly', C=400, epsilon=25, coef0=15).fit(X_train_scaled, y_train)\n",
        "svr_Y_pred = svr.predict(X_test_scaled)\n",
        "print(f'SVR; {mean_squared_error(y_test, svr_Y_pred) / 100000000}') #good\n",
        "\n",
        "print()\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, svr, tree; {mean_squared_error(y_test, Y_pred) / 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred], axis=0)\n",
        "print(f'linear, svr; {mean_squared_error(y_test, Y_pred) / 100000000}')\n",
        "\n",
        "Y_pred = np.mean([svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'svr, tree; {mean_squared_error(y_test, Y_pred) / 100000000}') #best\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, tree; {mean_squared_error(y_test, Y_pred) / 100000000}') "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression; 23.098707477530354\n",
            "DecisionTreeRegressor; 20.56496764724979\n",
            "SVR; 24.76449909334306\n",
            "\n",
            "linear, svr, tree; 21.047850671527886\n",
            "linear, svr; 23.269784707437626\n",
            "svr, tree; 21.21656208803024\n",
            "linear, tree; 19.978360770000677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad5sT8oVOtVi",
        "outputId": "ea90a9e4-dbef-48c9-bb0f-a628c48e57cd"
      },
      "source": [
        "#次元削減（1列目削除）\n",
        "\n",
        "linear = LinearRegression().fit(X_train_scaled[:,0].reshape(-1,1), y_train)\n",
        "linear_Y_pred = linear.predict(X_test_scaled[:,0].reshape(-1,1))\n",
        "print(f'LinearRegression; {mean_squared_error(y_test, linear_Y_pred) / 100000000}')\n",
        "\n",
        "tree = DecisionTreeRegressor(max_depth=5, min_samples_leaf=10).fit(X_train_scaled[:,0].reshape(-1,1), y_train)\n",
        "tree_Y_pred = tree.predict(X_test_scaled[:,0].reshape(-1,1))\n",
        "print(f'DecisionTreeRegressor; {mean_squared_error(y_test, tree_Y_pred) / 100000000}')\n",
        "\n",
        "svr = SVR(kernel='poly', C=400, epsilon=25, coef0=15).fit(X_train_scaled[:,0].reshape(-1,1), y_train) #best (単位：億)\n",
        "svr_Y_pred = svr.predict(X_test_scaled[:,0].reshape(-1,1))\n",
        "print(f'SVR; {mean_squared_error(y_test, svr_Y_pred) / 100000000}')\n",
        "\n",
        "print()\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, svr, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred], axis=0)\n",
        "print(f'linear, svr; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'svr, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}') "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression; 34.78476223193823\n",
            "DecisionTreeRegressor; 37.45350854184568\n",
            "SVR; 38.62927186329794\n",
            "\n",
            "linear, svr, tree; 36.42667167244415\n",
            "linear, svr; 36.504338710096356\n",
            "svr, tree; 37.5432562926157\n",
            "linear, tree; 35.62930191955775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t8thcUyPg70",
        "outputId": "f1d12a0b-d0c1-4f74-ffc4-e03df8fac0c1"
      },
      "source": [
        "#次元削減（0列目削除） ※良い結果得られず\n",
        "\n",
        "linear = LinearRegression().fit(X_train_scaled[:,1].reshape(-1,1), y_train)\n",
        "linear_Y_pred = linear.predict(X_test_scaled[:,1].reshape(-1,1))\n",
        "print(f'LinearRegression; {mean_squared_error(y_test, linear_Y_pred) / 100000000}')\n",
        "\n",
        "tree = DecisionTreeRegressor().fit(X_train_scaled[:,1].reshape(-1,1), y_train)\n",
        "tree_Y_pred = tree.predict(X_test_scaled[:,1].reshape(-1,1))\n",
        "print(f'DecisionTreeRegressor; {mean_squared_error(y_test, tree_Y_pred) / 100000000}')\n",
        "\n",
        "svr = SVR(C=300).fit(X_train_scaled[:,1].reshape(-1,1), y_train)\n",
        "svr_Y_pred = svr.predict(X_test_scaled[:,1].reshape(-1,1))\n",
        "print(f'SVR; {mean_squared_error(y_test, svr_Y_pred) / 100000000}')\n",
        "\n",
        "print()\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, svr, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred], axis=0)\n",
        "print(f'linear, svr; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'svr, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, tree; {mean_squared_error(y_test, Y_pred)/ 100000000}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression; 53.78966293259382\n",
            "DecisionTreeRegressor; 47.86023914334054\n",
            "SVR; 61.13540481769159\n",
            "\n",
            "linear, svr, tree; 50.50274469991106\n",
            "linear, svr; 55.73078171791606\n",
            "svr, tree; 50.51105236202921\n",
            "linear, tree; 48.08566821826108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgqeYBY0yo3v"
      },
      "source": [
        "#GrLivAreaカラムの外れ値除外\n",
        "limit_low=df['GrLivArea'].quantile(.5)\n",
        "limit_high=df['GrLivArea'].quantile(.95)\n",
        "\n",
        "df_selected = df.query('not @limit_low < GrLivArea < @limit_high')\n",
        "\n",
        "X = df_selected[['GrLivArea', 'YearBuilt']].values\n",
        "y = df_selected['SalePrice'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STxQ_nIj2GMf",
        "outputId": "e116fb4a-8f65-4b23-98b7-a18eee65d2ea"
      },
      "source": [
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "linear = LinearRegression().fit(X_train_scaled, y_train)\n",
        "linear_Y_pred = linear.predict(X_test_scaled)\n",
        "print(f'LinearRegression; {mean_squared_error(y_test, linear_Y_pred) / 100000000}')\n",
        "\n",
        "tree = DecisionTreeRegressor(max_depth=5, min_samples_leaf=10).fit(X_train_scaled, y_train)\n",
        "tree_Y_pred = tree.predict(X_test_scaled)\n",
        "print(f'DecisionTreeRegressor; {mean_squared_error(y_test, tree_Y_pred) / 100000000}')\n",
        "\n",
        "svr = SVR(kernel='poly', C=400, epsilon=25, coef0=15).fit(X_train_scaled, y_train)\n",
        "svr_Y_pred = svr.predict(X_test_scaled)\n",
        "print(f'SVR; {mean_squared_error(y_test, svr_Y_pred) / 100000000}') #good\n",
        "\n",
        "print()\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, svr, tree; {mean_squared_error(y_test, Y_pred) / 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred], axis=0)\n",
        "print(f'linear, svr; {mean_squared_error(y_test, Y_pred) / 100000000}')\n",
        "\n",
        "Y_pred = np.mean([svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'svr, tree; {mean_squared_error(y_test, Y_pred) / 100000000}') #best\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, tree; {mean_squared_error(y_test, Y_pred) / 100000000}') "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression; 27.064227625751375\n",
            "DecisionTreeRegressor; 29.638022391294385\n",
            "SVR; 27.67105633409051\n",
            "\n",
            "linear, svr, tree; 26.64429462308935\n",
            "linear, svr; 26.54873539334852\n",
            "svr, tree; 27.692373625078\n",
            "linear, tree; 26.801880471308593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8icIKczRCu"
      },
      "source": [
        "# 【問題2】バギングのスクラッチ実装\n",
        "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
        "\n",
        "\n",
        "バギングとは\n",
        "バギングは入力データの選び方を多様化する方法です。訓練データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
        "\n",
        "\n",
        "推定結果の平均をとる部分はブースティングと同様の実装になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBukg-8uMkmc"
      },
      "source": [
        "import random\n",
        "\n",
        "temp = df[['GrLivArea', 'YearBuilt', 'SalePrice']].values.reshape(-1,3)\n",
        "\n",
        "def make_samples(temp=temp):\n",
        "  temp_array = np.array([])\n",
        "  samples = 10000\n",
        "\n",
        "  for i in range(samples):\n",
        "    v = random.randint(0, temp.shape[0] -1)\n",
        "    temp_array = np.append(temp_array, temp[v,:])\n",
        "\n",
        "  temp_array = temp_array.reshape(-1,3)\n",
        "\n",
        "  X = temp_array[:,:2]\n",
        "  y = temp_array[:,2]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "558jFqmtRawh",
        "outputId": "2b91a815-c394-43d0-cacf-af0a7ea9d94e"
      },
      "source": [
        "#10000サンプル作成\n",
        "X_train, X_test, y_train, y_test = make_samples()\n",
        "\n",
        "linear = LinearRegression().fit(X_train, y_train)\n",
        "linear_Y_pred = linear.predict(X_test)\n",
        "print(f'LinearRegression; {mean_squared_error(y_test, linear_Y_pred) / 100000000}')\n",
        "\n",
        "tree = DecisionTreeRegressor().fit(X_train, y_train)\n",
        "tree_Y_pred = tree.predict(X_test)\n",
        "print(f'DecisionTreeRegressor; {mean_squared_error(y_test, tree_Y_pred) / 100000000}')\n",
        "\n",
        "svr = SVR().fit(X_train, y_train)\n",
        "svr_Y_pred = svr.predict(X_test)\n",
        "print(f'SVR; {mean_squared_error(y_test, svr_Y_pred) / 100000000}') \n",
        "\n",
        "#決定木単独の結果が最良"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression; 21.468095301308658\n",
            "DecisionTreeRegressor; 0.27247049287199027\n",
            "SVR; 61.93585873471752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWZeotzDTG9-",
        "outputId": "2dd36952-1fb2-4437-81dd-9fd9f952e706"
      },
      "source": [
        "#平均を算出\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, svr, tree; {mean_squared_error(y_test, Y_pred) / 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, svr_Y_pred], axis=0)\n",
        "print(f'linear, svr; {mean_squared_error(y_test, Y_pred) / 100000000}')\n",
        "\n",
        "Y_pred = np.mean([svr_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'svr, tree; {mean_squared_error(y_test, Y_pred) / 100000000}')\n",
        "\n",
        "Y_pred = np.mean([linear_Y_pred, tree_Y_pred], axis=0)\n",
        "print(f'linear, tree; {mean_squared_error(y_test, Y_pred) / 100000000}') #best"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear, svr, tree; 13.792764589047465\n",
            "linear, svr; 30.73057966815517\n",
            "svr, tree; 15.649758459634432\n",
            "linear, tree; 5.572488329791733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSr3PaqIzRFb"
      },
      "source": [
        "# 【問題3】スタッキングのスクラッチ実装\n",
        "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
        "\n",
        "\n",
        "スタッキングとは\n",
        "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは \n",
        "K\n",
        "0\n",
        "=\n",
        "3\n",
        ",\n",
        "M\n",
        "0\n",
        "=\n",
        "2\n",
        " 程度にします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa7RWg25thyP"
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/data/house-prices-advanced-regression-techniques_train.csv')\n",
        "\n",
        "X = df[['GrLivArea', 'YearBuilt']].values\n",
        "y = df['SalePrice'].values\n",
        "\n",
        "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #訓練データとテストデータ"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X96WbsYZmFCY",
        "outputId": "093979b2-fae8-4a9b-8ed1-ca337858107a"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "model_1 = LinearRegression()\n",
        "model_5 = SVR(kernel='poly', C=400, epsilon=25, coef0=15)\n",
        "model_3 = RandomForestRegressor(max_depth=5, min_samples_leaf=10) \n",
        "model_6 = DecisionTreeRegressor(max_depth=5, min_samples_leaf=10) \n",
        "model_4 = Ridge() \n",
        "model_2 = Lasso() \n",
        "\n",
        "\n",
        "Fold = 8\n",
        "\n",
        "preds_array = np.zeros((1022,1)) #ブレンドデータ\n",
        "test_preds_array = np.zeros((292,1)) #テストデータ（推定結果）\n",
        "\n",
        "kf = KFold(n_splits=Fold, random_state=0, shuffle=True)\n",
        "\n",
        "for train_id,test_id in kf.split(X_train_valid):\n",
        "  #訓練データ、テストデータ作成\n",
        "  X_train ,y_train = X_train_valid[train_id], y_train_valid[train_id]\n",
        "  X_test_kford ,y_test_kford = X_train_valid[train_id], y_train_valid[train_id]\n",
        "\n",
        "  #モデル1、検証データにて推定、データ格納\n",
        "  reg = model_1.fit(X_train, y_train)\n",
        "  Y_pred_model_1 = reg.predict(X_test_kford).reshape(-1,1)\n",
        "  preds_array = np.append(preds_array, Y_pred_model_1, axis=1)\n",
        "  \n",
        "  #テストデータにて推定、データ格納  \n",
        "  Y_pred_model_1 = reg.predict(X_test).reshape(-1,1)\n",
        "  test_preds_array = np.append(test_preds_array, Y_pred_model_1, axis=1)\n",
        "\n",
        "  #モデル2、検証データにて推定、データ格納\n",
        "  reg = model_2.fit(X_train, y_train)\n",
        "  Y_pred_model_2 = reg.predict(X_test_kford).reshape(-1,1)\n",
        "  preds_array = np.append(preds_array, Y_pred_model_2, axis=1)\n",
        "\n",
        "  #テストデータにて推定、データ格納  \n",
        "  Y_pred_model_2 = reg.predict(X_test).reshape(-1,1)\n",
        "  test_preds_array = np.append(test_preds_array, Y_pred_model_2, axis=1)\n",
        "\n",
        "  #モデル3、検証データにて推定、データ格納\n",
        "  reg = model_3.fit(X_train, y_train)\n",
        "  Y_pred_model_3 = reg.predict(X_test_kford).reshape(-1,1)\n",
        "  preds_array = np.append(preds_array, Y_pred_model_3, axis=1)\n",
        "\n",
        "  #テストデータにて推定、データ格納  \n",
        "  Y_pred_model_3 = reg.predict(X_test).reshape(-1,1)\n",
        "  test_preds_array = np.append(test_preds_array, Y_pred_model_3, axis=1)\n",
        "\n",
        "  #モデル4、検証データにて推定、データ格納\n",
        "  reg = model_4.fit(X_train, y_train)\n",
        "  Y_pred_model_4 = reg.predict(X_test_kford).reshape(-1,1)\n",
        "  preds_array = np.append(preds_array, Y_pred_model_4, axis=1)\n",
        "\n",
        "  #テストデータにて推定、データ格納  \n",
        "  Y_pred_model_4 = reg.predict(X_test).reshape(-1,1)\n",
        "  test_preds_array = np.append(test_preds_array, Y_pred_model_4, axis=1)\n",
        "\n",
        "  #モデル5、検証データにて推定、データ格納\n",
        "  reg = model_5.fit(X_train, y_train)\n",
        "  Y_pred_model_5 = reg.predict(X_test_kford).reshape(-1,1)\n",
        "  preds_array = np.append(preds_array, Y_pred_model_5, axis=1)\n",
        "\n",
        "  #テストデータにて推定、データ格納  \n",
        "  Y_pred_model_5 = reg.predict(X_test).reshape(-1,1)\n",
        "  test_preds_array = np.append(test_preds_array, Y_pred_model_5, axis=1)\n",
        "\n",
        "meta_model = model_6\n",
        "meta_model.fit(preds_array[:,1:],  y_test_kford)\n",
        "\n",
        "# スタッキングの検証\n",
        "meta_test_pred = meta_model.predict(test_preds_array[:,1:])\n",
        "print(f'MSE; {mean_squared_error(y_test, meta_test_pred) / 100000000}') #best"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE; 18.91176634058408\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}