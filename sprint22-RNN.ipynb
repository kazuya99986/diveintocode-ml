{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "338998f9",
   "metadata": {},
   "source": [
    "# Sprint22 リカレントニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e1ee73-b449-48ed-8aa2-bbd5f94d6238",
   "metadata": {},
   "source": [
    "# 【問題1】SimpleRNNのフォワードプロパゲーション実装\n",
    "SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。ndarrayのshapeがどうなるかを併記しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f0738-c9d0-4f18-aac0-dafbf5a01fb0",
   "metadata": {},
   "source": [
    "# 【問題2】小さな配列でのフォワードプロパゲーションの実験\n",
    "小さな配列でフォワードプロパゲーションを考えてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9050824c-6e21-42dd-a358-77ccf66d7a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ScratchSimpleRNNClassifier:\n",
    "    '''\n",
    "    RNNのベースクラス\n",
    "    ---\n",
    "\n",
    "    '''\n",
    "    def __init__(self, w_x, w_h, batch_size, n_sequences, n_features, n_nodes, h, b):\n",
    "        self.w_x = w_x\n",
    "        self.w_h = w_h\n",
    "        self.batch_size = batch_size\n",
    "        self.n_sequences = n_sequences\n",
    "        self.n_features = n_features\n",
    "        self.h = h\n",
    "        self.b = b\n",
    "    \n",
    "\n",
    "    def fit(self, x):\n",
    "        '''\n",
    "        NN分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 次の形のndarray, shape (batch_size, n_features)\n",
    "            時刻tの入力\n",
    "        h　: 次の形のndarray, shape(batch_size, n_nodes)\n",
    "            時刻tの状態・出力\n",
    "        '''\n",
    "        #シーケンス数でループ\n",
    "        for i in range(self.n_sequences):\n",
    "            #hをprevへ代入\n",
    "            h_prev = self.h\n",
    "            #h_prevを送り、新たなhを得る\n",
    "            self.h = self.forward(x[:,i, :], h_prev)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        h : \n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        t = np.dot(h_prev, self.w_h) + np.dot(x, w_x) + self.b\n",
    "        h_next = self.Tanh(t)\n",
    "\n",
    "        return h_next\n",
    "    \n",
    "    def Tanh(self, t):\n",
    "        '''\n",
    "        活性化関数\n",
    "        '''\n",
    "        return np.tanh(t)\n",
    "\n",
    "\n",
    "#入力データ\n",
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)#バッチサイズ, タイムステップ, 次元(単変量なら１, 多変量なら2以上)\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)　#入力に対する重み\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)#状態に対する重み\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes) #隠れ状態ベクトル\n",
    "b = np.array([1, 1, 1, 1]) # (n_nodes,) #重み\n",
    "\n",
    "a = ScratchSimpleRNNClassifier(w_x, w_h, batch_size, n_sequences, n_features, n_nodes, h, b)\n",
    "a.fit(x)\n",
    "\n",
    "a.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a59f7-7787-4b5a-b17e-fc87da2007e3",
   "metadata": {},
   "source": [
    "# リカレントニューラルネットワーク（RNN）  \n",
    "- RNN=分散表現 BoWは局所表現　※要確認  \n",
    "- hはその時々の「状態」を表す。時間が1ステップ進むにつれて以下式で更新されていく、「隠れ状態」、もしくは「隠れ状態ベクトル」と呼ばれる  \n",
    "$a_t = x_{t}\\cdot W_{x} + h_{t-1}\\cdot W_{h} + B\\\\$\n",
    "$h_t = tanh(a_t)$  \n",
    "- DNNは時系列を考慮に入れることができない。RNNは時系列を考慮し、前後にどんなデータがあるかを重視する\n",
    "- xはループする。一方は前へ、一方は自分へ向かう（戻る）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34208f6f-ca57-4af2-be18-8f4ecfa3b96d",
   "metadata": {},
   "source": [
    "## シーケンスのモデル\n",
    "- one to one\n",
    "入力データも出力データも固定サイズのベクトルである一般のニューラルネット。\n",
    "\n",
    "- one to many\n",
    "入力データはシーケンスではないが、出力データはシーケンスである。\n",
    "例として、画像キャプショニングがある。\n",
    "画像キャプショニングでは、入力は画像であり、出力は英語のフレーズになる。\n",
    "\n",
    "- many to one\n",
    "入力データはシーケンスだが、出力データは固定サイズのベクトルである。\n",
    "例えば感情分析では、入力はテキストベースであり、出力はクラスラベルである。\n",
    "\n",
    "- many to many\n",
    "入力データも出力データもどちらもシーケンスである。\n",
    "これは入力と出力が同期するかに従って、さらに分類できる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
